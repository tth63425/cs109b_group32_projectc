{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Final Project Milestone 3 - LexRank Model\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2020**<br/>\n",
    "**Group 32** \n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as EDA\n",
    "# libraries\n",
    "import json\n",
    "import lzma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import datetime as dt\n",
    "import math\n",
    "from collections import Counter\n",
    "from rouge import Rouge \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>1. Introduction</a> \n",
    "- <a href='#2'>2. Citation Filter</a>\n",
    "- <a href='#3'>3. Importing the legal documents</a>\n",
    "- <a href='#4'>4. LexRank Implementation</a>\n",
    "- <a href='#5'>5. Examples</a>\n",
    "- <a href='#6'>6. Challenges to thematic segmentation</a>\n",
    "- <a href='#7'>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1'>1. Introduction</a>\n",
    "\n",
    "In order to summarize the legal texts, I choose the LexRank model, which is one of the ways for extractive summarization.\n",
    "\n",
    "There are two ways to summarize texts using NLP; extractive and abstractive. Since the extractive approach chooses sentences from the original text, it is less likely to create an incomprehensible summary and less likely to output a gramatically incorrect summary. However, in the extractive approach, you cannot use words that are not in the original text, so it is not possible to paraphrase or to use conjunctions to make summary more easy to read. In contrast, the abstractive allows you to summarize more flexibly because you are free to use words that are not in the original sentences. In addition, you can choose the length of summary. However, the disadvantage in this approach is that it is difficult to produce \"natural\" sentences. For this project, I decided to take the extractive way to ensure that important information is included in the summary of the legal documents.\n",
    "\n",
    "The LexRank model works almost the same as Google Search -- it uses sentences as a node and similarity as edge/weight. For details, please refer to [Erkan and Radev (2004)](https://www.aaai.org/Papers/JAIR/Vol22/JAIR-2214.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>2. Citation Filter</a>\n",
    "\n",
    "According to [Farzindar and Lapalme (2004)](https://www.aclweb.org/anthology/W04-1006.pdf), the citations account for a large part of the text of the judgment, but they are not considered relevant for the summary. Therefore, I removed sentences that include specific abbreviation or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Reference: https://library.csustan.edu/apalegal\n",
    "\n",
    "def citation_filter(text_list):\n",
    "    new_list = []\n",
    "    \n",
    "    for i in range(len(text_list)):\n",
    "        sentence = text_list[i]\n",
    "        \n",
    "        if re.search('\\(\\d\\d\\d\\d\\)', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('v\\.', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('vs\\.', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('§', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('R\\.', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('Rule', sentence) != None:\n",
    "            pass\n",
    "        # Ark. = Arkansas\n",
    "        elif re.search('Ark\\.', sentence) != None:\n",
    "            pass\n",
    "        else:\n",
    "            new_list.append(sentence)\n",
    "            \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3'>3. Importing the legal documents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as EDA\n",
    "# defining a fucnction to remove \\n and HTML tags\n",
    "def text_cleaner(text):\n",
    "    text_divided = text.splitlines()\n",
    "    text_divided_clean = \" \".join(text_divided)\n",
    "    return text_divided_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as EDA\n",
    "# The file size for some states are too large to open into memory\n",
    "# This function loads individual cases into memory, parses headnotes and \n",
    "# opinions, cleans the text, tokenizes the text, and returns counts of tokens\n",
    "# for each case.\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
    "\n",
    "def get_counts(state):\n",
    "    cases = []\n",
    "    with lzma.open(\"../\" + state + '-text/data/data.jsonl.xz', 'r') as jsonl_file:\n",
    "        for case in jsonl_file:\n",
    "            c = json.loads(str(case, 'utf-8'))\n",
    "\n",
    "            date = c['decision_date']\n",
    "            \n",
    "            headnotes = text_cleaner(c['casebody']['data']['head_matter'])\n",
    "            headnotes_tokenized = tokenizer.tokenize(headnotes)\n",
    "            num_headnotes = len(headnotes_tokenized)\n",
    "\n",
    "            opinions = c['casebody']['data']['opinions']\n",
    "            if opinions == []:\n",
    "                num_opinions = 0\n",
    "            else:\n",
    "                opinions = text_cleaner(opinions[0]['text'])\n",
    "                opinions_tokenized = tokenizer.tokenize(opinions)\n",
    "                num_opinions = len(opinions_tokenized)\n",
    "            cases.append({'date':date, 'num_headnotes':num_headnotes, 'headnotes': headnotes, 'num_opinions':num_opinions, 'opinions':opinions})\n",
    "        return pd.DataFrame(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 s, sys: 522 ms, total: 43.9 s\n",
      "Wall time: 43.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# use Arkansas data as an example\n",
    "states = ['Arkansas']\n",
    "counts_ar = get_counts(states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>num_headnotes</th>\n",
       "      <th>headnotes</th>\n",
       "      <th>num_opinions</th>\n",
       "      <th>opinions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1829-11</td>\n",
       "      <td>29</td>\n",
       "      <td>Case No. 4,822a. FISHER v. REIDER. [Hempst. 82...</td>\n",
       "      <td>230</td>\n",
       "      <td>OPINION OF THE COIÍRT. This is an action of de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1828-05</td>\n",
       "      <td>28</td>\n",
       "      <td>Case No. 4,785a. FIKES v. BENTLEY. [Hempst. 61...</td>\n",
       "      <td>62</td>\n",
       "      <td>OPINION OP THE COURT. This is an appeal from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1836-02</td>\n",
       "      <td>27</td>\n",
       "      <td>Case No. 4,863a. FLETCHER v. ELLIS. [Hempst. 3...</td>\n",
       "      <td>616</td>\n",
       "      <td>CROSS, Judge. The record in this case shows th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-07-15</td>\n",
       "      <td>46</td>\n",
       "      <td>Michael NORRIS v. STATE of Arkansas CR 98-1429...</td>\n",
       "      <td>3936</td>\n",
       "      <td>W. H.“Dub” Arnold, Chief Justice. This is a ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-10-07</td>\n",
       "      <td>39</td>\n",
       "      <td>Roger Allen HAMMON v. STATE of Arkansas CR 98-...</td>\n",
       "      <td>1788</td>\n",
       "      <td>Ray Thornton, Justice. Appellant brings this a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  num_headnotes  \\\n",
       "0     1829-11             29   \n",
       "1     1828-05             28   \n",
       "2     1836-02             27   \n",
       "3  1999-07-15             46   \n",
       "4  1999-10-07             39   \n",
       "\n",
       "                                           headnotes  num_opinions  \\\n",
       "0  Case No. 4,822a. FISHER v. REIDER. [Hempst. 82...           230   \n",
       "1  Case No. 4,785a. FIKES v. BENTLEY. [Hempst. 61...            62   \n",
       "2  Case No. 4,863a. FLETCHER v. ELLIS. [Hempst. 3...           616   \n",
       "3  Michael NORRIS v. STATE of Arkansas CR 98-1429...          3936   \n",
       "4  Roger Allen HAMMON v. STATE of Arkansas CR 98-...          1788   \n",
       "\n",
       "                                            opinions  \n",
       "0  OPINION OF THE COIÍRT. This is an action of de...  \n",
       "1  OPINION OP THE COURT. This is an appeal from t...  \n",
       "2  CROSS, Judge. The record in this case shows th...  \n",
       "3  W. H.“Dub” Arnold, Chief Justice. This is a ca...  \n",
       "4  Ray Thornton, Justice. Appellant brings this a...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_ar.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4'>4. LaxRank Implementation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute term frequency\n",
    "# Reference: http://www.tfidf.com/\n",
    "# sentence: dictionary\n",
    "def termfreq(sentence):\n",
    "\n",
    "    dict_counts = Counter(sentence)\n",
    "    max_tf = max(dict_counts.values())\n",
    "\n",
    "    tf_dict = {}\n",
    "    \n",
    "    # create a dictionary with word + term frequncy\n",
    "    for word, tf in dict_counts.items():\n",
    "        tf_dict[word] = tf / max_tf\n",
    "    \n",
    "    # Output Example: {'word': tf, 'word': tf, ...}\n",
    "    return tf_dict\n",
    "\n",
    "# Create a dictionary with words and their IDF: Inverse Document Frequncy\n",
    "# Reference: http://www.tfidf.com/\n",
    "# list_sentences: list\n",
    "def compute_idf(list_sentences):\n",
    "    \n",
    "    idf_dict = {}\n",
    "    sentences_len = len(list_sentences)\n",
    "\n",
    "    for sentence in list_sentences:\n",
    "        for word in sentence:\n",
    "            if word not in idf_dict:\n",
    "                \n",
    "                # if not in idf_dict, calculate idf and append it to the dictionary\n",
    "                number_appearance = 0\n",
    "                for sen in list_sentences:\n",
    "                    if word in sen:\n",
    "                        number_appearance += 1\n",
    "                idf_dict[word] = math.log(sentences_len / number_appearance)\n",
    "                \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html\n",
    "# Chapter 3 : Centrality-based Sentence Salience\n",
    "def idf_modified_cosine(list_sentences, list_sentence_x, list_sentence_y):\n",
    "    \n",
    "    dict_x = termfreq(list_sentence_x)\n",
    "    dict_y = termfreq(list_sentence_y)\n",
    "    idf_dict = compute_idf(list_sentences)\n",
    "\n",
    "    set_unique_words1 = set(list_sentence_x)\n",
    "    set_unique_words2 = set(list_sentence_y)\n",
    "\n",
    "    words_xy = set_unique_words1 & set_unique_words2\n",
    "    \n",
    "    numerator = 0\n",
    "    for word in words_xy:\n",
    "        numerator = numerator + dict_x[word] * dict_y[word] * ((idf_dict[word])**2)\n",
    "        \n",
    "    denominator_left_quad = 0\n",
    "    for word in set_unique_words1:\n",
    "        denominator_left_quad = denominator_left_quad + ((dict_x[word] * idf_dict[word]) ** 2)\n",
    "        \n",
    "    denominator_right_quad = 0\n",
    "    for word in set_unique_words2:\n",
    "        denominator_right_quad = denominator_right_quad + ((dict_y[word] * idf_dict[word]) ** 2)\n",
    "    \n",
    "    denominator_left = math.sqrt(denominator_left_quad)\n",
    "    denominator_right = math.sqrt(denominator_right_quad)\n",
    "    \n",
    "    if denominator_left == 0 or denominator_right == 0:\n",
    "        print(\"Error! 0 in denominator!\")\n",
    "    else:\n",
    "        return numerator / (math.sqrt(denominator_left) * math.sqrt(denominator_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html\n",
    "# 3.2 Eigenvector Centrality and LexRank\n",
    "# computing the stationary distribution of a Marcov chain\n",
    "def power_method(M, N, eps):\n",
    "\n",
    "    # initialization\n",
    "    p = np.full((N,), 1/N)\n",
    "\n",
    "    delta = 999\n",
    "\n",
    "    while delta >= eps:\n",
    "        p_t = np.dot(np.transpose(M), p)\n",
    "        delta = np.linalg.norm(p_t - p)\n",
    "        p = p_t\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html\n",
    "# 3.2 Eigenvector Centrality and LexRank, Algorithm #3\n",
    "\n",
    "# Lexrank: summarizing sentences\n",
    "# computing Lexrank Scores\n",
    "def lex_rank(list_sentences, n, t):\n",
    "\n",
    "    cosinematrix = np.zeros((n, n))\n",
    "    degree = np.zeros((n,))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cosinematrix[i][j] = idf_modified_cosine(list_sentences, list_sentences[i], list_sentences[j])\n",
    "            if cosinematrix[i][j] > t:\n",
    "                cosinematrix[i][j] = 1\n",
    "                degree[i] += 1\n",
    "            else:\n",
    "                cosinematrix[i][j] = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cosinematrix[i][j] = cosinematrix[i][j] / degree[i]\n",
    "\n",
    "    L = power_method(cosinematrix, n, t)\n",
    "\n",
    "    return zip(list_sentences, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5'>5. Examples</a>\n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opinions = counts_ar.iloc[2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CROSS, Judge. The record in this case shows that the plaintiff in error [Frederick Fletcher] brought an action of trespass on the case against the. defendant [William Ellis], in the Conway circuit court, and in his declaration alleged “that the said plaintiff and one Alexander Rogers, were indebted to Daniel Gilmore in a large sum of money, namely,' in the amount of fifty-five dollars, upon which said Gilmore had brought suit and obtained judgment, and sued out execution against the plaintiff and the said Rogers, and the plaintiff avers that he and Rogers had, in the county of Conway, sufficient goods and chattels to have satisfied the execution, and the plaintiff avers that the defendant being an evil disposed person, fond of encouraging litigation and fomenting strife, and wishing to harass, impoverish, and distress the plaintiff, did, on the first day of October, 1834, at the county of Conway, and within the jurisdiction of this court, maliciously persuade and procure the said Daniel Gilmore, by offering him to pay all costs and charges, and to see his debt made secure, to have the plaintiff's body taken in execution; and by reason of the defendant’s procurements by his several offers and promises as aforesaid made, the plaintiff’s body was taken in execution.” It also appears that the defendant filed a demurrer to the declaration, which was sustained by the court. The writ of error is prosecuted to reverse the judgment sustaining the demurrer. A mere glance at the declaration will show that it has been drawn by an extremely careless pleader. The object of the action doubtless was, to charge the defendant for a maintenance, which is defined to be an officious intermeddling in a suit depending in a court, with which the person so intermeddling has nothing to do, by assisting the plaintiff or defendant in the prosecution of such suit. Co. Litt. 358; 2 Inst. 213. The court is not designated in which the suit was pending, nor is the time or place alleged when arid where the execution issued or into whose hands it came. The allegation is in relation to the maintenance, that the defendant offered Gilmore to pay costs and charges, and to see that his debt was secured. Between a mere offer to assist and assistance, there is certainly a material difference, for without the latter, the maintenance is not committed at all. So far as anything can be collected on the subject from the declaration, it seems that at the time the offer was made to pay costs and see the debt secured, an execution was rightfully in the hands of an officer of some kind, and the plaintiff and Rogers had a sufficiency of property in the county to satisfy it If so, the defendant’s offers were made in relation to a matter over which neither he nor Gilmore had any control, as the officer was legally bound in the first place, to levy on and dispose of the property in satisfaction of the writ, notwithstanding the plaintiff in execution might have instructed him to arrest the body of the defendant That an action lies in this country for maintenance, we entertain but little doubt Tet it certainly would be necessary, in order to sustain such an action, to allege not only the pendency of a suit but designate the particular court in which it was depending, together with time and circumstances, none of which requisites exist in the case before ns. Indeed, there is scarcely a single requisite stated necessary to constitute a maintenance, and we have seldom had occasion to examine a declaration in which there was so frail a cause of action set forth. Judgment affirmed.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://nlpforhackers.io/splitting-text-into-sentences/\n",
    "\n",
    "from pprint import pprint\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    " \n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(test_opinions)\n",
    " \n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opinions_list = tokenizer.tokenize(test_opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer(text, n, t=1):\n",
    "    \"\"\"\n",
    "    n: number of sentences\n",
    "    t: error tolerance\n",
    "    \"\"\"\n",
    "    words_list = []\n",
    "    for i in range(len(text)):\n",
    "        words = text[i].split()\n",
    "        words_list.append(words)\n",
    "    zipped = lex_rank(words_list, len(text), t)\n",
    "    unzipped = list(zip(*zipped))\n",
    "    scores = np.array(unzipped[1])\n",
    "    highest_index = scores.argsort()[-n:][::-1]\n",
    "    summarized = []\n",
    "    high_scores = []\n",
    "    for i in range(len(highest_index)):\n",
    "        sentence = text[i]\n",
    "        score = scores[i]\n",
    "        high_scores.append(score)\n",
    "        summarized.append(sentence)     \n",
    "    print(\"\\nOriginally\", len(text), \"sentences\\n\")\n",
    "    print(\"Summarized in\", n, \"sentences\\n\")\n",
    "    print(\"Summarized:  \", summarized,\"\\n\")\n",
    "    return summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Originally 14 sentences\n",
      "\n",
      "Summarized in 4 sentences\n",
      "\n",
      "Summarized:   ['CROSS, Judge.', 'The record in this case shows that the plaintiff in error [Frederick Fletcher] brought an action of trespass on the case against the.', \"defendant [William Ellis], in the Conway circuit court, and in his declaration alleged “that the said plaintiff and one Alexander Rogers, were indebted to Daniel Gilmore in a large sum of money, namely,' in the amount of fifty-five dollars, upon which said Gilmore had brought suit and obtained judgment, and sued out execution against the plaintiff and the said Rogers, and the plaintiff avers that he and Rogers had, in the county of Conway, sufficient goods and chattels to have satisfied the execution, and the plaintiff avers that the defendant being an evil disposed person, fond of encouraging litigation and fomenting strife, and wishing to harass, impoverish, and distress the plaintiff, did, on the first day of October, 1834, at the county of Conway, and within the jurisdiction of this court, maliciously persuade and procure the said Daniel Gilmore, by offering him to pay all costs and charges, and to see his debt made secure, to have the plaintiff's body taken in execution; and by reason of the defendant’s procurements by his several offers and promises as aforesaid made, the plaintiff’s body was taken in execution.” It also appears that the defendant filed a demurrer to the declaration, which was sustained by the court.\", 'The writ of error is prosecuted to reverse the judgment sustaining the demurrer.'] \n",
      "\n",
      "CPU times: user 380 ms, sys: 5.03 ms, total: 385 ms\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 616 words\n",
    "result1 = text_summarizer(citation_filter(test_opinions_list), 4, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Headnote:  Case No. 4,863a. FLETCHER v. ELLIS. [Hempst. 300.] Superior Court, Territory of Arkansas. Feb. 1836. Before CROSS and TELL, Judges. 1 [Reported by Samuel H. Hempstead, Esq.] \n",
      "\n",
      "\n",
      "Rouge F1 Score: 0.02205882162440544\n"
     ]
    }
   ],
   "source": [
    "string1 = ''.join(result1)\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(string1, counts_ar.iloc[2,2])\n",
    "print(\"Original Headnote: \", counts_ar.iloc[2,2], \"\\n\\n\")\n",
    "print(\"Rouge F1 Score:\", scores[0]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_opinions = counts_ar.iloc[182,4]\n",
    "test2_opinions_list = tokenizer.tokenize(test2_opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Originally 44 sentences\n",
      "\n",
      "Summarized in 15 sentences\n",
      "\n",
      "Summarized:   ['Battle, J.', 'The Bank of Malvern sued J. W. Burton and William Kilpatrick, in the Hot Springs circuit court, upon a note executed by them to it for the sum of $349.50, bearing date the 12th day of May, 1896, and due ninety days after date.', 'The defendants answered, and pleaded usury.', 'The plaintiff filed a reply, which, on motion of defendants, was stricken from the files of the court.', 'As it was not restored to record by bill of exceptions, it is no longer in the ea.se.', 'The cause, both parties consenting, was submitted to the court sitting as a jury.', 'J. W. Burton testified as follows on his own behalf: “I am one of the defendants in the above-entitled cause, and I executed the note sued on herein.', 'The note was due ninety days from its date.', 'I paid $16.00 interest in advance for the extension of the note, which note was for $349.50, dated May 12, 1896, which interest was in excess of ten per cent, per annum, and was an intentional usurious charge of interest for the ninety day’s forbearance, and was agreed to by the parties.', 'The note on its face drew ten per cent, per annum from maturity until paid.” Cross-Examination.', '“Í did not get any money from the Bank of Malvern.', 'The note sued on was given for another that I had in the bank.', 'I never did get a dollar from the bank.', 'This note, the one sued on herein, was given for a former note, and is for the same amount that the original note was given for, exactly.', 'I think my first dealings with the Bank of Malvern were in 1894.'] \n",
      "\n",
      "CPU times: user 7.71 s, sys: 64.6 ms, total: 7.77 s\n",
      "Wall time: 7.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result2 = text_summarizer(citation_filter(test2_opinions_list), 15, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Headnote:  Bank of Malvern v. Burton. Opinion delivered February 10, 1900. 1. Usury—Renewal Note.—Where the note sued on was the last of a series of usurious notes given in renewal of a note untainted with usury, plaintiff was entitled to amend the complaint so as to recover on the original note. (Page 429.) 2. Pleading—Amendment to Conform to Proof.—Where no objection was taken to the admission of evidence that the note sued on was given in renewal of a valid note, the complaint was properly treated by the trial court as amended to conform to the proof. (Page 429.) Appeal from Hot Springs Circuit Court. Alexander M. Duffie, Judge. JS. M. Vance, Jr., for appellant. It was error to strike appellant’s reply from the files. 44 S. W. 393; 99 N. Car. 107. The usury, if any, in the renewal notes did not affect the consideration, which was free from usury. Hence the pleadings should have been considered amended by the proof, and judgment given for the original debt. 29 Ark. 323; 42 Ark. 57; 55 Ark. 143; 56 Ark. 334; 35 Ark. 217; 98 N. Car, 107; 27 Am. & Eng. Enc. Law, 946-7. Jesse B. Moore, for appellee. The court was correct in sustaining the motion to strike. 33 Ark. 56, 593; 44 Ark. 293; 48 Ark. 238. Since the first note was usurious and void, the debt is destroyed. 53 Ark. 271; 56 Ark. 143, 146. The court below had the right to disregard incompetent and irrelevant evidence, and it was its duty to do so. 42 Ark. 310; 4 Ark. 251. It was discretionary with the court to treat the complaint as amended or not. 22 Ark. 164; 23 Ark.„735; 54 Ark. 444. The evidence as to the debt was irrelevant, under the pleading. 46 Ark. 96. \n",
      "\n",
      "\n",
      "Rouge F1 Score: 0.36148648149219326\n"
     ]
    }
   ],
   "source": [
    "string2 = ''.join(result2)\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(string2, counts_ar.iloc[182,2])\n",
    "print(\"Original Headnote: \", counts_ar.iloc[182,2], \"\\n\\n\")\n",
    "print(\"Rouge F1 Score:\", scores[0]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_opinions = counts_ar.iloc[175,4]\n",
    "test3_opinions_list = tokenizer.tokenize(test3_opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Originally 32 sentences\n",
      "\n",
      "Summarized in 20 sentences\n",
      "\n",
      "Summarized:   ['Hughes, J., (after stating the facts.)', 'The question arises on the construction of several statutes relating to county convicts.', '• The act of March 10, 1877, provides as follows: “Sec.', '4.', 'When any person shall be convicted of any misdemeanor under the laws of this state by any court of competent jurisdiction, the court shall render judgment against the person so convicted, which judgment shall direct that the person convicted be put to labor in any manual labor workhouse, or on any bridge or other public improvement, or that the person be hired out to some person as hereinafter provided, until the fine and costs are paid, and which shall not exceed one day for each seventy-five cents of the fine and costs.” Acts 1877, p.', '74; Sand.', '& H.', 'The following is taken from the act of March 22, 1881: “Sec.', '5.', 'That whenever any prisoner shall be convicted of a misdemeanor by any court or justice of the peace, if the fine and costs are not immediately paid or secured to be paid within thirty days to the satisfaction of the constable, sheriff or other officer, in case of conviction before the circuit court, said convict shall be committed to the county jail, and by the jailer delivered to the contractor, who shall keep and work him at the rate of twenty-five cents per day, not including Sundays and days on which said convicts shall be unable to labor, or for any cause, by his consent, shall not labor, and said contractor shall pay said fine and costs, and be liable on his bond for the same; and he shall not be released or excused therefrom unless said convict shall die without working sufficient to pay the same; or unless said convict shall be or become, from continued ill health, unable to work.', 'In such case the county judge may order his discharge without payment of costs; but, unless so discharged, said convict shall work two days for each day lost by sickness, one of which days shall be for compensation of keeping him during a day on which he was sick; and whenever said convict shall be sentenced to jail as a part of his punishment, he shall first work with the contractor to pay his fine and costs, and shall then commence to serve out his term by labor under the contractor as herein provided.” Acts 1881, p.', '150.', 'The act of March 13, 1883, provides as follows: “See.', '3.', 'That section 5 of said act be so amended as to read as follows: See.', '5.', 'Whenever any prisoner shall be convicted of a misdemeanor by any court or justice of the peace, if the fine and costs are not immediately paid or secured to be paid within thirty days to the satisfaction of the constable, sheriff or other officer, in case of conviction before the circuit court, said convict shall be committed to the county jail, and by the jailor delivered to the contractor at such place as the contractor may designate, who shall keep and work such prisoners for the time he shall have been adjudged to be imprisoned, and for the further time as will discharge all fines and costs for which he may be committed, at the rate of fifty (50) cents per day.', 'And said contractor shall not be released or excused from payinn for the time of any convict unless such convict shall die without having labored, or unless such convict shall be or become from continued ill-health unable to work.', 'In such case the county judge may order such convict to be discharged without payment of fine or costs, and whenever any convict shall be sentenced to jail, as part of his punishment, he shall first work with the contractor to pay his fine and costs, and shall then commence to serve out his term by labor under the contractor as herein provided.” Acts 1883, p.', '126.'] \n",
      "\n",
      "CPU times: user 4.22 s, sys: 11.4 ms, total: 4.23 s\n",
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result3 = text_summarizer(citation_filter(test3_opinions_list), 20, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Headnote:  State v. McNally. Opinion delivered March 10, 1900. County Convict—Per Diem Allowance.—The act of April 12,1899 (? 3), relating to county convicts, which amended the act of March 13,1883, upon the same subject by increasing the per diem allowance of a county convict delivered to the county contractor from 50 cents to 75 cents per day was not intended to be retroactive, nor to apply to the case of one convicted prior to its passage. (Page 583.)\" Appeal from Jefferson Circuit Court. Antonio B. Grace, Judge. STATEMENT BY THE COURT. Petition by appellee for habeas corpus, alleging as follows: On the 6th of April, 1899, appellee was convicted of an assault in the court below, and fined $50, making, with the costs, $109. On the 11th of the month she was committed to the custody of R. R. Adams, contractor for county prisoners of the county, where she has continuously served at hard labor; and she is entitled to credit in the month of April 19 days, May 31 days, June 30 days, July 31 days, August 31 days and September 11 days, in all 153 days, which at 75 cents a day, amounts to $114, or $4.35 more than the amount due. Adams answered as follows: Defendant entered into contract with the county judge of the county for keeping county prisoners from January 1, 1899, to January 1, 1900. He was to pay all costs of conviction of prisoners; to pay five and a half cents a day for their labor; and to provide them with proper food and clothing, and with medical attendance. Adams gave bond accordingly. He says appellee worked 84 and one-half days, and lost, on account of bad weather, Sundays, and sickness, 51 and a quarter days. Appellee was not allowed for time thus lost; but for the time that she labored she was allowed 50 cents a day, making $45.12|-; a statement which was admitted by the petitioner. The court allowed petitioner for the full time claimed 153 days, at 75 cents a day, and discharged her. Motion for a new trial was filed by the appellant, raising all questions of law. It was overruled, and appellant excepted. An appeal was prayed and granted. Jeff Davis, Attorney General, Ghas. Jacobson, W. B. Sorrells, Prosecuting Attorney, and Bose, Hemingivay Bose, for appellant. The amended statute of 1883 supersedes the statutes of 1877 and 1881, aud fixes the amount to be allowed prisoners per diem at fifty cents. Compare Act March 10, 1877, (Sand. & H. Dig., § 899), § 4; Acts 1881, p. 150, sec. 5; Acts 1883, p. 126, secs. 3 and 5. That the latter act repeals the former, see: Endlieh, Stat. Const § 196; 67 N. Y. 109; 49 N. Y. 332; Holmes, 245, S. C. Fed. Cas. No. 17,247; 143 U. S. 18; 65 Ark. 210. In allowing compensation by the day, Sundays are not to be counted. 58 Ark. 620; 92 Ala. 96; 77 id. 597; 12 Ga. 100; 8 Mete. 496; 26 Enc. Law, 14. The act of 1899 has no application, because it has no retroactive effect. 56 Ark. 495. Habeas corpus cannot be made to perform the office of an appeal or writ of error. Hurd, Hab. Corp. ch. 6, § 2; 166 U. S. 552. \n",
      "\n",
      "\n",
      "Rouge F1 Score: 0.33388157398680973\n"
     ]
    }
   ],
   "source": [
    "string3 = ''.join(result3)\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(string3, counts_ar.iloc[175,2])\n",
    "print(\"Original Headnote: \", counts_ar.iloc[175,2], \"\\n\\n\")\n",
    "print(\"Rouge F1 Score:\", scores[0]['rouge-1']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6'>6. Challenges to thematic segmentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Farzindar and Lapalme (2004)](https://www.aclweb.org/anthology/W04-1006.pdf), thematic segmentation by linguistic markars is introduced as a way to more easily summarize legal documents. This is because we can follow the structure of legal documets, and we are less likely to miss important information. I tried to implement the thematic segmentation, but I observed, for example, linguistic markars for conclusion in the beginning of a legal document. Therefore, I decided not to use thematic segmentation for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.aclweb.org/anthology/W04-1006.pdf\n",
    "\n",
    "markars_introduction = ['application for judicial review', 'application to review a decision', 'motion filed by', 'Statement of Claim']\n",
    "\n",
    "markars_context = [\"advise\",\"indicate\",\"concern\",\"request\"]\n",
    "\n",
    "markars_juridical_analysis = ['this court','In reviewing',\n",
    "                            'Pursuant to section','As I have stated','In the present case']\n",
    "\n",
    "markars_conclusion = ['note','accept','summarise','scrutinize','think','say','satisfy','discuss','conclude','find','believe','reach','persuade',\n",
    "                      'agree','indicate','review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "markars = [markars_introduction, markars_context, markars_juridical_analysis, markars_conclusion]\n",
    "\n",
    "def markar_detector(text_list):\n",
    "    for i in range(len(text_list)):\n",
    "        sentence = text_list[i]\n",
    "        \n",
    "        for markar in markars:\n",
    "            for j in range(len(markar)):\n",
    "                markar_word = markar[j]\n",
    "                TF = markar_word in sentence\n",
    "                if TF == True:\n",
    "                    if markar == markars_context:\n",
    "                        type_markar = \"context\"\n",
    "                        print(\"Linguistic markar '\"+markar_word+\"' detected! Sentence #\", i, \"of \"+str(len(text_list))+\". This is\",type_markar,\"markar.\")\n",
    "                    elif markar == markars_juridical_analysis:\n",
    "                        type_markar = \"juridical analysis\"\n",
    "                        print(\"Linguistic markar '\"+markar_word+\"' detected! Sentence #\", i, \"of \"+str(len(text_list))+\". This is\",type_markar,\"markar.\") \n",
    "                    else:\n",
    "                        type_markar = \"conclusion\"\n",
    "                        print(\"Linguistic markar '\"+markar_word+\"' detected! Sentence #\", i, \"of \"+str(len(text_list))+\". This is\",type_markar,\"markar.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic markar 'find' detected! Sentence # 9 of 607. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 28 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 28 of 607. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 64 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 64 of 607. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 92 of 607. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 97 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 99 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 111 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 111 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 141 of 607. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 145 of 607. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 148 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 151 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 153 of 607. This is context markar.\n",
      "Linguistic markar 'note' detected! Sentence # 168 of 607. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 172 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 174 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 174 of 607. This is conclusion markar.\n",
      "Linguistic markar 'advise' detected! Sentence # 176 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 180 of 607. This is context markar.\n",
      "Linguistic markar 'think' detected! Sentence # 195 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 196 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 197 of 607. This is conclusion markar.\n",
      "Linguistic markar 'think' detected! Sentence # 198 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 199 of 607. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 202 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 205 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 225 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 228 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 236 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 245 of 607. This is context markar.\n",
      "Linguistic markar 'request' detected! Sentence # 247 of 607. This is context markar.\n",
      "Linguistic markar 'say' detected! Sentence # 249 of 607. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 250 of 607. This is context markar.\n",
      "Linguistic markar 'find' detected! Sentence # 258 of 607. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 273 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 273 of 607. This is conclusion markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 274 of 607. This is conclusion markar.\n",
      "Linguistic markar 'this court' detected! Sentence # 303 of 607. This is juridical analysis markar.\n",
      "Linguistic markar 'note' detected! Sentence # 304 of 607. This is conclusion markar.\n",
      "Linguistic markar 'this court' detected! Sentence # 319 of 607. This is juridical analysis markar.\n",
      "Linguistic markar 'review' detected! Sentence # 319 of 607. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 327 of 607. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 328 of 607. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 356 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 362 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 370 of 607. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 372 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 379 of 607. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 396 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 396 of 607. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 416 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 439 of 607. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 441 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 445 of 607. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 523 of 607. This is conclusion markar.\n",
      "Linguistic markar 'concern' detected! Sentence # 530 of 607. This is context markar.\n",
      "Linguistic markar 'say' detected! Sentence # 536 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 540 of 607. This is conclusion markar.\n",
      "Linguistic markar 'think' detected! Sentence # 542 of 607. This is conclusion markar.\n",
      "Linguistic markar 'concern' detected! Sentence # 547 of 607. This is context markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 556 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 560 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 564 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 579 of 607. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 582 of 607. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 582 of 607. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 587 of 607. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 592 of 607. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 600 of 607. This is conclusion markar.\n",
      "Linguistic markar 'motion filed by' detected! Sentence # 601 of 607. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 605 of 607. This is conclusion markar.\n"
     ]
    }
   ],
   "source": [
    "test_text4 = counts_ar.iloc[5,4]\n",
    "test_text_list4 = tokenizer.tokenize(test_text4)\n",
    "\n",
    "markar_detector(test_text_list4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7'>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the LexRank Model summarizes the legal documents with a reasonably long headnote well (Rouge F1 Score around 0.35), there is a couple of ways to improve the LexRank model.\n",
    "\n",
    "- For example, we missed conclusion (juridical decision) in Example 2. This is because I do not implement thematic segmentation and the model cannot recognize the conclusion sentences as important.\n",
    "- Regarding thematic segmentation, we should have better lists of linguistic markars. In addition, we could set a stop condition for thematic segmentation (e.g. if we observe conclusion markars N times in a row, we recognize all the texts after that as conclusion.)\n",
    "- We should also think about the citation filter as headnotes include citations especially in conclusion. We should not the citation filter for summarizing conclusion. (But in order to achieve it, we need to implement thematic segmentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
