{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Final Project Milestone 3 - LexRank Model\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2020**<br/>\n",
    "**Group 32** \n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as EDA\n",
    "# libraries\n",
    "import json\n",
    "import lzma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import datetime as dt\n",
    "import math\n",
    "from collections import Counter\n",
    "from rouge import Rouge \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>1. Introduction</a> \n",
    "- <a href='#2'>2. Citation Filter</a>\n",
    "- <a href='#3'>3. Importing the legal documents</a>\n",
    "- <a href='#4'>4. LexRank Implementation</a>\n",
    "- <a href='#5'>5. Examples</a>\n",
    "- <a href='#6'>6. Challenges to thematic segmentation</a>\n",
    "- <a href='#7'>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1'>1. Introduction</a>\n",
    "\n",
    "In order to summarize the legal texts, we also test the LexRank model, which is one of the ways for extractive summarization.\n",
    "\n",
    "There are two ways to summarize texts using NLP; extractive and abstractive. Since the extractive approach chooses sentences from the original text, it is less likely to create an incomprehensible summary and less likely to output a gramatically incorrect summary. However, in the extractive approach, you cannot use words that are not in the original text, so it is not possible to paraphrase or to use conjunctions to make summary more easy to read. In contrast, the abstractive allows you to summarize more flexibly because you are free to use words that are not in the original sentences. In addition, you can choose the length of summary. However, the disadvantage in this approach is that it is difficult to produce \"natural\" sentences. For this project, we decided to take the extractive way to ensure that important information is included in the summary of the legal documents.\n",
    "\n",
    "The LexRank model works almost the same as Google Search -- it uses sentences as a node and similarity as edge/weight. For details, please refer to [Erkan and Radev (2004)](https://www.aaai.org/Papers/JAIR/Vol22/JAIR-2214.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>2. Citation Filter</a>\n",
    "\n",
    "According to [Farzindar and Lapalme (2004)](https://www.aclweb.org/anthology/W04-1006.pdf), the citations account for a large part of the text of the judgment, but they are not considered relevant for the summary. Therefore, I removed sentences that include specific abbreviation or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Reference: https://library.csustan.edu/apalegal\n",
    "\n",
    "def citation_filter(text_list):\n",
    "    new_list = []\n",
    "    \n",
    "    for i in range(len(text_list)):\n",
    "        sentence = text_list[i]\n",
    "        \n",
    "        if re.search('\\(\\d\\d\\d\\d\\)', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('v\\.', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('vs\\.', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('§', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('R\\.', sentence) != None:\n",
    "            pass\n",
    "        elif re.search('Rule', sentence) != None:\n",
    "            pass\n",
    "        # Ark. = Arkansas\n",
    "        elif re.search('Ark\\.', sentence) != None:\n",
    "            pass\n",
    "        else:\n",
    "            new_list.append(sentence)\n",
    "            \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3'>3. Importing the legal documents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as EDA\n",
    "# defining a fucnction to remove \\n and HTML tags\n",
    "def text_cleaner(text):\n",
    "    text_divided = text.splitlines()\n",
    "    text_divided_clean = \" \".join(text_divided)\n",
    "    return text_divided_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as EDA\n",
    "# The file size for some states are too large to open into memory\n",
    "# This function loads individual cases into memory, parses headnotes and \n",
    "# opinions, cleans the text, tokenizes the text, and returns counts of tokens\n",
    "# for each case.\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
    "\n",
    "def get_counts(state):\n",
    "    cases = []\n",
    "    with lzma.open(\"../\" + state + '-text/data/data.jsonl.xz', 'r') as jsonl_file:\n",
    "        for case in jsonl_file:\n",
    "            c = json.loads(str(case, 'utf-8'))\n",
    "\n",
    "            date = c['decision_date']\n",
    "            \n",
    "            headnotes = text_cleaner(c['casebody']['data']['head_matter'])\n",
    "            headnotes_tokenized = tokenizer.tokenize(headnotes)\n",
    "            num_headnotes = len(headnotes_tokenized)\n",
    "\n",
    "            opinions = c['casebody']['data']['opinions']\n",
    "            if opinions == []:\n",
    "                num_opinions = 0\n",
    "            else:\n",
    "                opinions = text_cleaner(opinions[0]['text'])\n",
    "                opinions_tokenized = tokenizer.tokenize(opinions)\n",
    "                num_opinions = len(opinions_tokenized)\n",
    "            cases.append({'date':date, 'num_headnotes':num_headnotes, 'headnotes': headnotes, 'num_opinions':num_opinions, 'opinions':opinions})\n",
    "        return pd.DataFrame(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 1.05 s, total: 1min 16s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# use North Carolina data as an example\n",
    "states = ['North Carolina']\n",
    "counts_nc = get_counts(states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4'>4. LaxRank Implementation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute term frequency\n",
    "# Reference: http://www.tfidf.com/\n",
    "# sentence: dictionary\n",
    "def termfreq(sentence):\n",
    "\n",
    "    dict_counts = Counter(sentence)\n",
    "    max_tf = max(dict_counts.values())\n",
    "\n",
    "    tf_dict = {}\n",
    "    \n",
    "    # create a dictionary with word + term frequncy\n",
    "    for word, tf in dict_counts.items():\n",
    "        tf_dict[word] = tf / max_tf\n",
    "    \n",
    "    # Output Example: {'word': tf, 'word': tf, ...}\n",
    "    return tf_dict\n",
    "\n",
    "# Create a dictionary with words and their IDF: Inverse Document Frequncy\n",
    "# Reference: http://www.tfidf.com/\n",
    "# list_sentences: list\n",
    "def compute_idf(list_sentences):\n",
    "    \n",
    "    idf_dict = {}\n",
    "    sentences_len = len(list_sentences)\n",
    "\n",
    "    for sentence in list_sentences:\n",
    "        for word in sentence:\n",
    "            if word not in idf_dict:\n",
    "                \n",
    "                # if not in idf_dict, calculate idf and append it to the dictionary\n",
    "                number_appearance = 0\n",
    "                for sen in list_sentences:\n",
    "                    if word in sen:\n",
    "                        number_appearance += 1\n",
    "                idf_dict[word] = math.log(sentences_len / number_appearance)\n",
    "                \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html\n",
    "# Chapter 3 : Centrality-based Sentence Salience\n",
    "def idf_modified_cosine(list_sentences, list_sentence_x, list_sentence_y):\n",
    "    \n",
    "    dict_x = termfreq(list_sentence_x)\n",
    "    dict_y = termfreq(list_sentence_y)\n",
    "    idf_dict = compute_idf(list_sentences)\n",
    "\n",
    "    set_unique_words1 = set(list_sentence_x)\n",
    "    set_unique_words2 = set(list_sentence_y)\n",
    "\n",
    "    words_xy = set_unique_words1 & set_unique_words2\n",
    "    \n",
    "    numerator = 0\n",
    "    for word in words_xy:\n",
    "        numerator = numerator + dict_x[word] * dict_y[word] * ((idf_dict[word])**2)\n",
    "        \n",
    "    denominator_left_quad = 0\n",
    "    for word in set_unique_words1:\n",
    "        denominator_left_quad = denominator_left_quad + ((dict_x[word] * idf_dict[word]) ** 2)\n",
    "        \n",
    "    denominator_right_quad = 0\n",
    "    for word in set_unique_words2:\n",
    "        denominator_right_quad = denominator_right_quad + ((dict_y[word] * idf_dict[word]) ** 2)\n",
    "    \n",
    "    denominator_left = math.sqrt(denominator_left_quad)\n",
    "    denominator_right = math.sqrt(denominator_right_quad)\n",
    "    \n",
    "    if denominator_left == 0 or denominator_right == 0:\n",
    "        print(\"Error! 0 in denominator!\")\n",
    "    else:\n",
    "        return numerator / (math.sqrt(denominator_left) * math.sqrt(denominator_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html\n",
    "# 3.2 Eigenvector Centrality and LexRank\n",
    "# computing the stationary distribution of a Marcov chain\n",
    "def power_method(M, N, eps):\n",
    "\n",
    "    # initialization\n",
    "    p = np.full((N,), 1/N)\n",
    "\n",
    "    delta = 999\n",
    "\n",
    "    while delta >= eps:\n",
    "        p_t = np.dot(np.transpose(M), p)\n",
    "        delta = np.linalg.norm(p_t - p)\n",
    "        p = p_t\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html\n",
    "# 3.2 Eigenvector Centrality and LexRank, Algorithm #3\n",
    "\n",
    "# Lexrank: summarizing sentences\n",
    "# computing Lexrank Scores\n",
    "def lex_rank(list_sentences, n, t):\n",
    "\n",
    "    cosinematrix = np.zeros((n, n))\n",
    "    degree = np.zeros((n,))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cosinematrix[i][j] = idf_modified_cosine(list_sentences, list_sentences[i], list_sentences[j])\n",
    "            if cosinematrix[i][j] > t:\n",
    "                cosinematrix[i][j] = 1\n",
    "                degree[i] += 1\n",
    "            else:\n",
    "                cosinematrix[i][j] = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cosinematrix[i][j] = cosinematrix[i][j] / degree[i]\n",
    "\n",
    "    L = power_method(cosinematrix, n, t)\n",
    "\n",
    "    return zip(list_sentences, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5'>5. Examples</a>\n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opinions = counts_nc.iloc[97597,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MORRIS, Chief Judge. The sole issue on appeal is whether claimants, were discharged because of misconduct associated with their work and are thus disqualified from receiving unemployment benefits. Findings of fact of the Commission are conclusive if supported by the evidence, and judicial review is limited to determining whether errors of law have been committed. G.S. 96-15(i). The findings of fact to which appellant excepts are as follows: 5. The employer alleged they were discharged as a result of having found gambling for money while on company property and during a work day. 6. Each of the parties (claimants) involved denies having done any gambling for money. Each party (claimant) does agree that they were playing cards for a game or two, but not with any betting for money involved. Someone had found an incomplete deck of cards and while waiting for job assignments the four claimants fooled around playing a hand or two of cards. 7. The claimants were not playing cards for money and were not therefore gambling as the employer alleged. An employer witness stated that he thought they were gambling, but had not seen any money being passed. He had only observed washers on what might have been used as a card table. We hold that these findings are fully supported by the testimony given at the hearing and reflected in the record. The findings of fact are, therefore, binding on appeal. We hold, furthermore, that the facts support the Commission’s conclusion that the claimants were not discharged for misconduct in connection with their work. An employee will be disqualified for benefits if it is determined that he was discharged for misconduct connected with his work. G.S. 96-14(2). “Misconduct” as. that word is used in unemployment compensation law has been defined as . . . conduct evincing such wilful or wanton disregard of an employer’s interest as is found in deliberate violations or disregard of standards of behavior which the employer has the right to expect of his employee. . . . In Re Collingsworth, 17 N.C. App. 340, 343-44, 194 S.E. 2d 210, 212-13 (1973), quoting Boynton Cab Company v. Neubeck, 237 Wis. 249, 259, 296 N.W. 636, 640 (1941), where the Wisconsin Court noted that “mere inefficiency, unsatisfactory conduct . . . are not to be deemed ‘misconduct’ . . .”. Id. at 260, 296 N.W. at 640. The facts support a conclusion that there was no wilful or wanton disregard of the employer’s interest. Claimants were accused of and discharged for gambling. There is no evidence that the men’s card playing amounted to gambling, however. Appellant made no showing that money was passed, or that the washers on the make-shift table around which the employees sat had any value, or that they represented something of value. Appellant argues that its rule against gambling need not be limited to gambling for money. Every definition adduced by the parties depicts gambling as a game of chance in which money or something of value is at stake, however. The criminal offense of gambling in North Carolina, for example, is described as “any game of chance at which any money, property, or other thing of value is bet.” G.S. 14-292. There is absolutely no evidence that the claimants’ play was for anything, tangible or intangible, of value or exchangeable for value. It is clear from the record and briefs that gambling among employees is prohibited by Walter Kidde and Company, Inc. Card playing, though perhaps undesirable at the workplace, was not explicitly prohibited. Claimants’ conduct, therefore, violated no rule, and the Commission could legitimately conclude that claimants were not engaged in conduct evincing substantial disregard for the standard of behavior to which they were expected to adhere. The judgment of the Superior Court is, for the reasons stated above, Affirmed. Judges Vaughn and Martin (Harry C.) concur.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://nlpforhackers.io/splitting-text-into-sentences/\n",
    "\n",
    "from pprint import pprint\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    " \n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(test_opinions)\n",
    " \n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opinions_list = tokenizer.tokenize(test_opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer(text, n, t=1):\n",
    "    \"\"\"\n",
    "    n: number of sentences\n",
    "    t: error tolerance\n",
    "    \"\"\"\n",
    "    words_list = []\n",
    "    for i in range(len(text)):\n",
    "        words = text[i].split()\n",
    "        words_list.append(words)\n",
    "    zipped = lex_rank(words_list, len(text), t)\n",
    "    unzipped = list(zip(*zipped))\n",
    "    scores = np.array(unzipped[1])\n",
    "    highest_index = scores.argsort()[-n:][::-1]\n",
    "    summarized = []\n",
    "    high_scores = []\n",
    "    for i in range(len(highest_index)):\n",
    "        sentence = text[i]\n",
    "        score = scores[i]\n",
    "        high_scores.append(score)\n",
    "        summarized.append(sentence)     \n",
    "    print(\"\\nOriginally\", len(text), \"sentences\\n\")\n",
    "    print(\"Summarized in\", n, \"sentences\\n\")\n",
    "    print(\"Summarized:  \", summarized,\"\\n\")\n",
    "    return summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Originally 47 sentences\n",
      "\n",
      "Summarized in 7 sentences\n",
      "\n",
      "Summarized:   ['MORRIS, Chief Judge.', 'The sole issue on appeal is whether claimants, were discharged because of misconduct associated with their work and are thus disqualified from receiving unemployment benefits.', 'Findings of fact of the Commission are conclusive if supported by the evidence, and judicial review is limited to determining whether errors of law have been committed.', 'G.S. 96-15(i).', 'The findings of fact to which appellant excepts are as follows: 5.', 'The employer alleged they were discharged as a result of having found gambling for money while on company property and during a work day.', '6.'] \n",
      "\n",
      "CPU times: user 7.19 s, sys: 3.96 ms, total: 7.2 s\n",
      "Wall time: 7.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 616 words\n",
    "result1 = text_summarizer(citation_filter(test_opinions_list), 7, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Headnote:  IN THE MATTER OF: WALTER KIDDE & COMPANY, INC., Post Office Box 509, Mebane, North Carolina 27302 v. JACK D. BRADSHAW, Route 1, Box 365, Mebane, North Carolina 27302, SS. No. [ XXX-XX-XXXX ], Docket No. 4235 G; ED FISHER, Route 8, Box 123, Burlington, North Carolina 27215, SS. No. [ XXX-XX-XXXX ], Docket No. 4242 G; GRADY L. HUNDLEY, Route 2, Box 576, Graham, North Carolina 27253, SS. No. [ XXX-XX-XXXX ], Docket No. 4247 G; DAVID A. TUTTLE, Route 8, Box 165, Burlington, North Carolina 27215, SS. No. [ XXX-XX-XXXX ], DOCKET No. 4277 G; AND EMPLOYMENT SECURITY COMMISSION OF NORTH CAROLINA, Post Office Box 25903, Raleigh, North Carolina 27611 No. 8115SC524 (Filed 6 April 1982) Haynsworth, Baldwin, Miles, Johnson, Greaves and Edwards, by Charles P. Roberts, for plaintiff appellant. Gail C. Arneke and C. Coleman Billingsley, Jr., for Employment Security Commission of North Carolina, appellee. \n",
      "\n",
      "\n",
      "Rouge F1 Score: 0.06530611770095829 Rouge F2 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "string1 = ''.join(result1)\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(string1, counts_nc.iloc[97597,2])\n",
    "print(\"Original Headnote: \", counts_nc.iloc[97597,2], \"\\n\\n\")\n",
    "print(\"Rouge F1 Score:\", scores[0]['rouge-1']['f'], \"Rouge F2 Score:\", scores[0]['rouge-2']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_opinions = counts_nc.iloc[97577,4]\n",
    "test2_opinions_list = tokenizer.tokenize(test2_opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Originally 26 sentences\n",
      "\n",
      "Summarized in 15 sentences\n",
      "\n",
      "Summarized:   ['Walker, J. Plaintiff alleged ownership, under a grant from the State t.o himself, of a tract of land containing 74 acres, more or less, on the north side of Pamlico Eiver and the west side of Bath Creek and designated on the court map by the figures 1, 2, 3, 4, 5, and back to 1, and on which the trespass was alleged to have been committed by cutting timber.', 'Defendant denied plaintiff’s title upon two grounds: 1.', \"That it had acquired title to the land under a deed of Jesse C. Bryan to Thomas D. Beasley, dated 19 March, 1846, and a deed from James E. Shepherd, commissioner to sell the lands of the said Thomas D. Beasley, who had died, dated '2 June, 1882, and adverse possession under these deeds.\", 'Plaintiff claimed that the line 2 to 5, as shown on the map, is the western boundary of the deed of Bryan to Beasley, while the defendant contended that its western boundary is the line B, 0, 3.', '2.', \"There was a dispute between the parties as to' whether the deed from Bryan to Beasley covered the locus in quo, but the defendant further contended that this was immaterial, as the plaintiff’s own testimony, which defeats his recovery, was as follows: “The Archbell land lies west of the Beasley land.\", 'John Archbell and those claiming under him have been in possession of the land adjoining the Beasley land on the west ever since I have known it — fifty years or more.', 'Beasley and those claiming under him had been in possession of the Beasley land as long as I can recollect.', 'John B. Eespass is the only man who has ever shown me the water oak, figuré 5, as the Windley corner.', 'I live in about 2% miles from the land in controversy and make no claim to any part of the land in there except that little piece covered by my entry.', 'The Kug-ler Lumber Company bought the timber on the John Arehbell land, or Stickney land, as it was called.', 'The Archbell house stands within 100 yards of the mouth of Bath Creek.', 'The Beasley land is one of the oldest settlements in that neighborhood.', 'The cleared land on the William J. Archbell land is about a mile from this land.” There was evidence as to the possession of defendant, and those under whom it claimed, of the land covered by the deeds of James E. Shepherd, commissioner, and Bryan to Beasley; but it is not necessary to set it out, in the view we take of the case.', 'Judgment was entered for defendant, and plaintiff appealed.'] \n",
      "\n",
      "CPU times: user 3.55 s, sys: 4.04 ms, total: 3.56 s\n",
      "Wall time: 3.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result2 = text_summarizer(citation_filter(test2_opinions_list), 15, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Headnote:  JOHN D. ELLIOTT v. ROANOKE RAILROAD AND LUMBER COMPANY. (Filed 22 September, 1915.) 1. Trespass — Title—Burden of Proof. The weakness of the defendant’s title to land will not avail the plaintiff in an action of trespass involving title, for he must recover, if at all, upon the strength of his own title. 2. Same — State Grants — Deeds and Conveyances — Color—Plaintiff’s Evidence. Where the plaintiff’s own evidence, in an action of trespass on lands involving title, tends to show sufficient adverse possession of the defendant under color to take the title out of the State and ripen it in defendant, or in one under whom he claims, and the plaintiff is claiming the locus in quo by grant from the State, issued after the title had ripened, he cannot recover. Appeal by plaintiff from Justice, J., at February Term, 1915, of BEAUFORT. Civil action for trespass on land. Daniel & Warren and Bryan & Stewart for plaintiff. Small, McLean, Bragaw & Rodman for defendants. \n",
      "\n",
      "\n",
      "Rouge F1 Score: 0.24143555881214263 Rouge F2 Score: 0.05564647719126463\n"
     ]
    }
   ],
   "source": [
    "string2 = ''.join(result2)\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(string2, counts_nc.iloc[97577,2])\n",
    "print(\"Original Headnote: \", counts_nc.iloc[97577,2], \"\\n\\n\")\n",
    "print(\"Rouge F1 Score:\", scores[0]['rouge-1']['f'], \"Rouge F2 Score:\", scores[0]['rouge-2']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_opinions = counts_nc.iloc[97576,4]\n",
    "test3_opinions_list = tokenizer.tokenize(test3_opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Originally 80 sentences\n",
      "\n",
      "Summarized in 20 sentences\n",
      "\n",
      "Summarized:   ['Claek, C. J. Tbe General Assembly of 1913, chapters 248 and 276 placed tbe county of Pender within tbe public policy now prevailing over nine-tentbs of tbe territory of tbis State, under wbat is known as tbe “no-fence” law, by wbicb stock are not allowed to run at large on tbe lands of others than tbeir owners, and requires that such owners shall fence up tbeir stock instead of other people fencing them out in order to protect tbeir crops.', \"Tbe Legislature, by Public-Local Laws 1915, chapters 116 and 505, permitted tbe people of a certain part of Pender County to decide by vote whether they should return to tbe former system of letting' stock run at large, but made such provision, if adopted by such vote, dependent upon tbe condition precedent, that tbe change should not take effect until a fence should be constructed by such territory to prevent the stock therein trespassing upon tbe people of tbe adjoining counties in wbicb the owners of crops are protected by law against stock running at large.\", 'Tbe act further provided that in tbe tax levy to build such fence tbe property of natural persons in Eocky Point Township should be exempted.', 'VII, sec.', '9, which requires that “All taxes levied by any county, city, town, or township shall be uniform and act valorem upon all property in the same, except property exempt by the Constitution.” .', 'Under the laws in force, the property of the citizens is protected from stock running at large in the adjoining counties of Duplin, Sampson, Bladen, New Hanover, and Eocky Point Township in Pender; that is to say, in all the adjoining territory except Onslow on the east.', 'By the terms of the Acts in question, it was expressly provided that “It should not go into effect until the fence was built,” for the people of the adjoining territory were deemed by the Legislature to be entitled to the protection against stock running at large no matter whence they came, whether from their own territory or from the county of Pender.', 'Public-Local Laws 1917, ch.', '99, amended Eevisal, 1675, by placing Pender among the counties authorized to withdraw from stock-law territory upon a vote of the people upon compliance with certain provisions, and repealed “all laws in conflict therewith.” The proposition was thereupon submitted to the people and adopted; but the fence around the territory in Pender voting to withdraw has-not yet been built.', 'Eevisal, 1675, contains as the first proviso the following as a condition for the withdrawal of any territory from the stock-law territory after such vote has been had in its favor: \"Provided, the expense incurred in changing the fence in such boundary, district, or territory so released be paid by the property holders in such boundary, district; or territory, and that the commissioners of the county levy the tax to pay the same on the property holders of such boundary, district or territory so released, but shall not be further liable for keeping up said stock-law fence.” Upon the election held after such amendment to Eevisal, 1675, the majority voted to withdraw from the stock-law territory all the county outside of Eocky Point.Township.', 'theye were restrained from levying the tax because it was laid upon all property, both real and personal, and was therefore void because not authorized by a vote and no appeal was taken.', \"The commissioners then levied the tax as an assessment, and this was enjoined'because it was not authorized by the statute in question.\", 'Comrs., 175 N. C., 268.', 'Thereupon the defendants and others who wished their stock to run at large turned them out notwithstanding the provision that the stock-law fence must first be erected had not been complied with.', 'There is no repeal, express or implied, of such requirement, for it does not conflict with Revisal, 1675.', 'This conduct by defendants is enjoined bythe order of the judge in this case.', 'The action of the judge is in accordance with the law and must be sustained.', '• 1.', 'Revisal, 1675, under which the vote to change to stock running at large was held, contains a proviso that the “expense incurred in changing the fence” in territory wishing to return to the former condition of stock running át large must be paid by the property holders of such district.', 'The defendants contend that such provision amounts to nothing because the fences in Pender having been abolished since 1 March, 1913, putting-up such fence is not “changing the fence.” This is “sticking in the bark.” The evident intent, and the only possible meaning of the provision, is to require a fence to be put up for the protection of the territory left in the stock-law territory where the people are still to be protected against stock running at large.'] \n",
      "\n",
      "CPU times: user 5min 35s, sys: 3.56 ms, total: 5min 35s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result3 = text_summarizer(citation_filter(test3_opinions_list), 20, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Headnote:  D. H. MARSHBURN et als. v. ISAAC JONES et als. (Filed 27 November, 1918.) 1. Statutes — Stock—No-Fence Law — “Change of Fence.” The requirement of Revisal, sec. 1675, that the counties therein named may withdraw from the operation of the no-fence law, upon the conditions specified therein, if funds are provided by a tax levy, etc., for “changing the fence,” is to provide against trespass by the running at large of stock into no-fence territory, and contemplates the change from the one system to the other; and the position is untenable that the statute is inapplicable when the fence has long since been lawfully removed or destroyed. 2. Statutes — Repealing Statutes — Conflict—Stock—No-Fence Law — Fences. Where a statute amends Revisal, sec. 1675, by adding a part of another county to those therein named as having the right to withdraw from the stock law under certain conditions, and makes the .building of the fence around the outer boundaries of the proposed district a condition precedent to the exercise of this right, repealing conflicting laws, the condition imposed by the later statute is not in conflict with the provisions of the section of the Revisal requiring that the expense of the fence be met by a tax levy, etc. 3. Statutes — Public Policy — Stock—No-Fence Law — Fences. Our public policy with respect to the running of stock at large has been-changed by our statutes on the subject of “no-fence” or stock laws, and the uniformity, with slight exception, of their application to the entire State; and while Revisal, sec. 1675, permits the counties therein enumerated to withdraw, upon certain conditions, from “stock-law” territory, this is to be done with regard to the rights of those districts where the law is effective, requiring that the districts withdrawing therefrom shall erect the boundary fences necessary to keep tbe stock from trespassing upon tbe rights of tbe larger class of people within tbe “no-fence” territory. 4. Statutes — Repealing Statutes — Conflict—Stock—Fences—No-Fence Law. The act of 1917, placing Pender County among those specified in Re-visal, see. 1675, as having the right to withdraw from stock-law territory, etc., by repealing all laws in conflict therewith, does not affect the provision in the Public-Local Laws of 1915 relating to Pender County, and requiring as a condition precedent that, before its operative effect, a fence shall be built around the defined district. 5. Injunction — Public Policy — Multiplicity of Suits — Stock—No-Fence Law. Where a proposed “no-fence” district has' not been established according to the statute (Revisal, sec. 1675), equitable relief by injunction will lie against those who permit their stock to run at large and trespass upon the rights of others, upon the ground that such is against the well settled policy of the State; and that multiplicity of suits will be prevented. Hoke and Allen, JJ., dissent. Th-is is an appeal by defendants from tbe order of Stacy, J., continuing to tbe bearing a restraining order against tbe defendants allowing tbeir live-stock to run at large in Pender County, wbicb was beard by consent of all parties at Wilmington, 8 July, 1918. G. E. McGullen and G. D. Weeks for plaintiffs. J. II. Burnett and John D. Bellamy & Son for defendants. \n",
      "\n",
      "\n",
      "Rouge F1 Score: 0.43625644323212864 Rouge F2 Score: 0.1269372645582061\n"
     ]
    }
   ],
   "source": [
    "string3 = ''.join(result3)\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(string3, counts_nc.iloc[97576,2])\n",
    "print(\"Original Headnote: \", counts_nc.iloc[97576,2], \"\\n\\n\")\n",
    "print(\"Rouge F1 Score:\", scores[0]['rouge-1']['f'], \"Rouge F2 Score:\", scores[0]['rouge-2']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rouge F1 & F2 With the first 100 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarizer_simple(text, n, t=1):\n",
    "    \"\"\"\n",
    "    n: number of sentences\n",
    "    t: error tolerance\n",
    "    \"\"\"\n",
    "    words_list = []\n",
    "    for i in range(len(text)):\n",
    "        words = text[i].split()\n",
    "        words_list.append(words)\n",
    "    zipped = lex_rank(words_list, len(text), t)\n",
    "    unzipped = list(zip(*zipped))\n",
    "    scores = np.array(unzipped[1])\n",
    "    highest_index = scores.argsort()[-n:][::-1]\n",
    "    summarized = []\n",
    "    high_scores = []\n",
    "    for i in range(len(highest_index)):\n",
    "        sentence = text[i]\n",
    "        score = scores[i]\n",
    "        high_scores.append(score)\n",
    "        summarized.append(sentence)     \n",
    "    return summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rouge F1 Score: 0.3725000474930513 \n",
      "\n",
      "Average Rouge F2 Score: 0.13328381119168312\n",
      "CPU times: user 13min 11s, sys: 504 ms, total: 13min 12s\n",
      "Wall time: 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# use texts shorter than 2000 to save computation\n",
    "\n",
    "score_100_f1 = 0\n",
    "score_100_f2 = 0\n",
    "\n",
    "counter = 0\n",
    "counter_100 = 0\n",
    "\n",
    "while counter_100 < 100:\n",
    "    \n",
    "    row_num = 57000 + counter\n",
    "    \n",
    "    if counts_nc.iloc[row_num,3] > 2000:\n",
    "        counter += 1\n",
    "    else:\n",
    "        test100_opinions = counts_nc.iloc[row_num,4]\n",
    "        test100_opinions_list = tokenizer.tokenize(test100_opinions)\n",
    "\n",
    "        result100 = text_summarizer_simple(citation_filter(test100_opinions_list), 20, 0.1)\n",
    "\n",
    "        string100 = ''.join(result100)\n",
    "\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(string100, counts_nc.iloc[row_num,2])\n",
    "\n",
    "        score_100_f1 += scores[0]['rouge-1']['f']\n",
    "        score_100_f2 += scores[0]['rouge-2']['f']\n",
    "        \n",
    "        counter += 1\n",
    "        counter_100 += 1\n",
    "        \n",
    "print(\"Average Rouge F1 Score:\", score_100_f1 / 100, \"\\n\")\n",
    "print(\"Average Rouge F2 Score:\", score_100_f2 / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='6'>6. Challenges to thematic segmentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Farzindar and Lapalme (2004)](https://www.aclweb.org/anthology/W04-1006.pdf), thematic segmentation by linguistic markars is introduced as a way to more easily summarize legal documents. This is because we can follow the structure of legal documets, and we are less likely to miss important information. We tried to implement the thematic segmentation, but we observed, for example, linguistic markars for conclusion in the beginning of a legal document. Therefore, we decided not to use thematic segmentation for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.aclweb.org/anthology/W04-1006.pdf\n",
    "\n",
    "markars_introduction = ['application for judicial review', 'application to review a decision', 'motion filed by', 'Statement of Claim']\n",
    "\n",
    "markars_context = [\"advise\",\"indicate\",\"concern\",\"request\"]\n",
    "\n",
    "markars_juridical_analysis = ['this court','In reviewing',\n",
    "                            'Pursuant to section','As I have stated','In the present case']\n",
    "\n",
    "markars_conclusion = ['note','accept','summarise','scrutinize','think','say','satisfy','discuss','conclude','find','believe','reach','persuade',\n",
    "                      'agree','indicate','review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "markars = [markars_introduction, markars_context, markars_juridical_analysis, markars_conclusion]\n",
    "\n",
    "def markar_detector(text_list):\n",
    "    for i in range(len(text_list)):\n",
    "        sentence = text_list[i]\n",
    "        \n",
    "        for markar in markars:\n",
    "            for j in range(len(markar)):\n",
    "                markar_word = markar[j]\n",
    "                TF = markar_word in sentence\n",
    "                if TF == True:\n",
    "                    if markar == markars_context:\n",
    "                        type_markar = \"context\"\n",
    "                        print(\"Linguistic markar '\"+markar_word+\"' detected! Sentence #\", i, \"of \"+str(len(text_list))+\". This is\",type_markar,\"markar.\")\n",
    "                    elif markar == markars_juridical_analysis:\n",
    "                        type_markar = \"juridical analysis\"\n",
    "                        print(\"Linguistic markar '\"+markar_word+\"' detected! Sentence #\", i, \"of \"+str(len(text_list))+\". This is\",type_markar,\"markar.\") \n",
    "                    else:\n",
    "                        type_markar = \"conclusion\"\n",
    "                        print(\"Linguistic markar '\"+markar_word+\"' detected! Sentence #\", i, \"of \"+str(len(text_list))+\". This is\",type_markar,\"markar.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic markar 'find' detected! Sentence # 6 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 7 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 9 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 29 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 29 of 615. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 43 of 615. This is conclusion markar.\n",
      "Linguistic markar 'concern' detected! Sentence # 44 of 615. This is context markar.\n",
      "Linguistic markar 'say' detected! Sentence # 61 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 75 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 75 of 615. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 106 of 615. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 111 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 119 of 615. This is conclusion markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 121 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 131 of 615. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 141 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 146 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 146 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 155 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 160 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 161 of 615. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 161 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 162 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 162 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 163 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 164 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 164 of 615. This is conclusion markar.\n",
      "Linguistic markar 'concern' detected! Sentence # 173 of 615. This is context markar.\n",
      "Linguistic markar 'concern' detected! Sentence # 177 of 615. This is context markar.\n",
      "Linguistic markar 'find' detected! Sentence # 198 of 615. This is conclusion markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 207 of 615. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 210 of 615. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 217 of 615. This is conclusion markar.\n",
      "Linguistic markar 'agree' detected! Sentence # 218 of 615. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 229 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 231 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 231 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 232 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 241 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 245 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 256 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 290 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 293 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 294 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 294 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 295 of 615. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 295 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 296 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 296 of 615. This is conclusion markar.\n",
      "Linguistic markar 'reach' detected! Sentence # 297 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 299 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 302 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 305 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 310 of 615. This is context markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 310 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 310 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 311 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 311 of 615. This is conclusion markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 316 of 615. This is conclusion markar.\n",
      "Linguistic markar 'think' detected! Sentence # 318 of 615. This is conclusion markar.\n",
      "Linguistic markar 'think' detected! Sentence # 321 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 326 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 329 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 333 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 338 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 339 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 339 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 343 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 343 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 348 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 351 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 352 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 355 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 356 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 358 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 361 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 366 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 379 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 379 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 381 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 384 of 615. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 384 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 389 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 391 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 393 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 399 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 399 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 402 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 404 of 615. This is conclusion markar.\n",
      "Linguistic markar 'In the present case' detected! Sentence # 405 of 615. This is juridical analysis markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 405 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 410 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 414 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 417 of 615. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 419 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 421 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 421 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 424 of 615. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 425 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 427 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 427 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 430 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 433 of 615. This is conclusion markar.\n",
      "Linguistic markar 'say' detected! Sentence # 435 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 435 of 615. This is conclusion markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 439 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 447 of 615. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 452 of 615. This is context markar.\n",
      "Linguistic markar 'find' detected! Sentence # 452 of 615. This is conclusion markar.\n",
      "Linguistic markar 'think' detected! Sentence # 473 of 615. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 485 of 615. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 485 of 615. This is conclusion markar.\n",
      "Linguistic markar 'believe' detected! Sentence # 486 of 615. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 502 of 615. This is context markar.\n",
      "Linguistic markar 'say' detected! Sentence # 509 of 615. This is conclusion markar.\n",
      "Linguistic markar 'concern' detected! Sentence # 511 of 615. This is context markar.\n",
      "Linguistic markar 'find' detected! Sentence # 511 of 615. This is conclusion markar.\n",
      "Linguistic markar 'review' detected! Sentence # 516 of 615. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 519 of 615. This is context markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 527 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 529 of 615. This is conclusion markar.\n",
      "Linguistic markar 'In the present case' detected! Sentence # 535 of 615. This is juridical analysis markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 537 of 615. This is context markar.\n",
      "Linguistic markar 'find' detected! Sentence # 537 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 537 of 615. This is conclusion markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 540 of 615. This is context markar.\n",
      "Linguistic markar 'indicate' detected! Sentence # 540 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 546 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 550 of 615. This is conclusion markar.\n",
      "Linguistic markar 'request' detected! Sentence # 554 of 615. This is context markar.\n",
      "Linguistic markar 'find' detected! Sentence # 554 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 557 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 561 of 615. This is conclusion markar.\n",
      "Linguistic markar 'In the present case' detected! Sentence # 579 of 615. This is juridical analysis markar.\n",
      "Linguistic markar 'say' detected! Sentence # 580 of 615. This is conclusion markar.\n",
      "Linguistic markar 'find' detected! Sentence # 585 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 600 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 604 of 615. This is conclusion markar.\n",
      "Linguistic markar 'note' detected! Sentence # 605 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 607 of 615. This is conclusion markar.\n",
      "Linguistic markar 'conclude' detected! Sentence # 608 of 615. This is conclusion markar.\n",
      "Linguistic markar 'accept' detected! Sentence # 614 of 615. This is conclusion markar.\n"
     ]
    }
   ],
   "source": [
    "test_text4 = counts_nc.iloc[10,4]\n",
    "test_text_list4 = tokenizer.tokenize(test_text4)\n",
    "\n",
    "markar_detector(test_text_list4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='7'>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the LexRank Model summarizes the legal documents with a reasonably long headnote well (Example 2 and 3), the average Rouge F1 and F2 are not so good because we fixed the length of summary to be 20 and it is not flexible. There is a couple of ways to improve the LexRank model.\n",
    "\n",
    "- We might miss conclusion (juridical decision) because we do not implement thematic segmentation and the model cannot recognize the conclusion sentences as important.\n",
    "- Regarding thematic segmentation, we should have better lists of linguistic markars. In addition, we could set a stop condition for thematic segmentation (e.g. if we observe conclusion markars N times in a row, we recognize all the texts after that as conclusion.)\n",
    "- We should also think about the citation filter as headnotes include citations especially in conclusion. We should not the citation filter for summarizing conclusion. (But in order to achieve it, we need to implement thematic segmentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
